{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count eggs using roboflow trained roboflow 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SupervisionWarnings: BoundingBoxAnnotator is deprecated: `BoundingBoxAnnotator` is deprecated and has been renamed to `BoxAnnotator`. `BoundingBoxAnnotator` will be removed in supervision-0.26.0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import supervision as sv\n",
    "from inference import get_roboflow_model\n",
    "import torch\n",
    "import onnxruntime as rt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(image_slice: np.ndarray) -> sv.Detections:\n",
    "    results = model.infer(image_slice, confidence=0.45, iou_threshold=0.5)[0] # Reset confidence level here\n",
    "    return sv.Detections.from_inference(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_eggs(image_path):\n",
    "    # Read image path\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Decode the QR code in the image\n",
    "    qcd = cv2.QRCodeDetector()\n",
    "\n",
    "    retval, decoded_info, points, straight_qrcode = qcd.detectAndDecodeMulti(image)\n",
    "    points\n",
    "\n",
    "    if not retval:\n",
    "        decoded_info = [os.path.basename(image_path)]\n",
    "    else:\n",
    "        # Calculate the center of the square\n",
    "        center = np.mean(points, axis=1)\n",
    "\n",
    "        # Expand the points by the specified factors\n",
    "        scale_x = 1.6\n",
    "        scale_y = 2.25\n",
    "        expanded_points = np.copy(points)\n",
    "        expanded_points[:, :, 0] = scale_x * (points[:, :, 0] - center[:, 0]) + center[:, 0]\n",
    "        expanded_points[:, :, 1] = scale_y * (points[:, :, 1] - center[:, 1]) + center[:, 1]\n",
    "\n",
    "        # Convert points to integer coordinates\n",
    "        expanded_points = expanded_points.astype(int)\n",
    "\n",
    "        # Create a mask with the same dimensions as the image\n",
    "        mask = np.ones(image.shape[:2], dtype=np.uint8) * 255\n",
    "\n",
    "        # Fill the mask with the expanded points\n",
    "        cv2.fillPoly(mask, expanded_points, 0)\n",
    "\n",
    "        # Apply the mask to the image to remove the specified points\n",
    "        image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Slice Image and run inference using callback function\n",
    "    slicer = sv.InferenceSlicer(callback=callback, slice_wh=(640, 640))\n",
    "    sliced_detections = slicer(image=image)\n",
    "\n",
    "    # Save output image\n",
    "    box_annotator = sv.BoxAnnotator()\n",
    "    # You can also use sv.MaskAnnotator() for instance segmentation models\n",
    "    # mask_annotator = sv.MaskAnnotator()\n",
    "    annotated_image = box_annotator.annotate(\n",
    "        scene=image.copy(), detections=sliced_detections)\n",
    "    # Convert the annotated image from numpy array to PIL Image\n",
    "    image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "    annotated_image_pil = Image.fromarray(image_rgb)\n",
    "    annotated_image_resized = annotated_image_pil.resize((4000, 6000))\n",
    "    annotated_image_resized.save(f'/Users/path/to/output/{decoded_info[0]}.png')\n",
    "\n",
    "    # Save information to create a pandas df for export\n",
    "    class_names = sliced_detections['class_name']\n",
    "    class_id = sliced_detections.class_id\n",
    "    confidence = sliced_detections.confidence\n",
    "\n",
    "    # save objects into a single df\n",
    "    df = (pd.DataFrame({'ID': class_names, 'class_id': class_id, 'confidence': confidence})\n",
    "        .value_counts(subset = 'ID')\n",
    "        .to_frame(decoded_info[0])\n",
    "        .T.assign(total_eggs = len(sliced_detections)))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, CPUExecutionProvider'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0117.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0116.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0114.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0128.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0129.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0115.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0139.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0111.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0110.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0138.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0112.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0113.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0122.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0137.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0123.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0135.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0121.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0120.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0134.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0118.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0130.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0124.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0125.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0131.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0119.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0127.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0133.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0132.JPG', '/Users/aja294/Documents/Trout_local/egg_count/images/input/2024_11_01_egg_images/IMG_0126.JPG']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:00:56.177158 [W:onnxruntime:, coreml_execution_provider.cc:81 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 12 number of nodes in the graph: 233 number of nodes supported by CoreML: 220\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "directory = \"/Users/path/to/egg_images\"\n",
    "image_paths = [os.path.join(directory, filename) for filename in os.listdir(directory)]\n",
    "model = get_roboflow_model(model_id=\"egg_training-bi/1\", api_key=\"l6XPyOniqM4Ecq129cpf\")\n",
    "print(image_paths)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Image run for model\n",
    "results = []\n",
    "\n",
    "# Process images sequentially using a for loop\n",
    "for image_path in image_paths:\n",
    "    try:\n",
    "        result = count_eggs(image_path)\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID            egg_eyed  egg_blank  egg_dead  total_eggs\n",
      "CX-021-2024       4786       1122         8        5916\n",
      "CX-039-2024       2303        443       505        3251\n",
      "CX-019-2024       1634        474      1150        3258\n",
      "IMG_0128.JPG      3130       1044         9        4183\n",
      "IMG_0129.JPG      2474       1069       917        4460\n",
      "CX-039-2024       2762        316         5        3083\n",
      "CX-038-2024       2711        600       661        3972\n",
      "IMG_0111.JPG      3082       1135         9        4226\n",
      "CX-036-2024       1687        658      1450        3795\n",
      "CX-031-2024       1367        760      1567        3694\n",
      "CX-023-2024       1822        947      1594        4363\n",
      "IMG_0113.JPG      2585        537         7        3129\n",
      "CX-028-2024        378        635      2491        3504\n",
      "CX-030-2024       4541        435        58        5034\n",
      "CX-022-2024       2242        593       879        3714\n",
      "CX-037-2024       2700        375       333        3408\n",
      "CX-034-2024        477        878      1342        2697\n",
      "IMG_0120.JPG      1943        481         4        2428\n",
      "CX-037-2024       2842        289         8        3139\n",
      "CX-021-2024       2197       1078      3179        6454\n",
      "CX-035-2024       4706       1404        12        6122\n",
      "CX-026-2024       1691        361       178        2230\n",
      "CX-020-2024       3676        877      1122        5675\n",
      "CX-035-2024       4347       1449       648        6444\n",
      "CX-033-2024        489        271       247        1007\n",
      "IMG_0127.JPG      3127       1036        12        4175\n",
      "CX-030-2024       4500        443        57        5000\n",
      "CX-025-2024       5377       1013      1017        7407\n",
      "CX-032-2024       2960        728        85        3773\n"
     ]
    }
   ],
   "source": [
    "# Combine all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(results)\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('/Users/path/to/data/output/egg_count_results.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg_counter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
